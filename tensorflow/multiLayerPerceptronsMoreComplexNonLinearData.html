<!DOCTYPE html>
<html lang="en">
<head>
    <title>Multi-Layer Perceptrons - Neural Networks for More Complex Non-Linear</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>

<h1>TensorFlow.js Linear Regression using single neuron</h1>
<p>See console for outputs.</p>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js" type="text/javascript"></script>

<script>

    // Generate input numbers from 1 to 20 inclusive.
    const INPUTS = [];
    for (let n = 1; n <= 20; n++) {

        INPUTS.push(n);

    }

    // Generate Outputs that are simply each input multiplied by itself,
    // to generate some non linear data.
    const OUTPUTS = [];
    for (n = 0; n < INPUTS.length; n++) {

        OUTPUTS.push(INPUTS[n] * INPUTS[n]);

    }

    // Input feature Array is 1 dimensional.
    const INPUTS_TENSOR = tf.tensor1d(INPUTS);

    // Output can stay 1 dimensional.
    const OUTPUTS_TENSOR = tf.tensor1d(OUTPUTS);

    function normalize(tensor, min, max)
    {
        // Attention: code inside tidy anonymous function will by monitored and 
        // manually created tensors will be automatically disposed of once
        // the function returns without you needing to call dispose yourself manually on 
        // each time only returned by the function tensors survive, function must not be an asynchronous
        const result = tf.tidy(function() {
            const MIN_VALUES = min || tf.min(tensor, 0);
            const MAX_VALUES = max || tf.max(tensor, 0);

            const TENSOR_SUBTRACT_MIN_VALUE = tf.sub(tensor, MIN_VALUES);
            const RANGE_SIZE = tf.sub(MAX_VALUES, MIN_VALUES);
            const NORMALIZED_VALUES = tf.div(TENSOR_SUBTRACT_MIN_VALUE, RANGE_SIZE);

            return {NORMALIZED_VALUES, MIN_VALUES, MAX_VALUES};

        });
        return result;
    }

    const FEATURE_RESULTS = normalize(INPUTS_TENSOR);

    console.log('Normalized values:');
    FEATURE_RESULTS.NORMALIZED_VALUES.print();

    console.log('Min values:');
    FEATURE_RESULTS.MIN_VALUES.print();

    console.log('Max values:');
    FEATURE_RESULTS.MAX_VALUES.print();


    ///////////////////////////

    // Now actually create and define model architecture.
    const model = tf.sequential();

    // We will use one dense layer with 3 neuron (units) and an input of 
    // 1 input feature values.
    // We will use one dense layer with 100 neuron (units) and an input of 
    // 1 input feature values.
    model.add(tf.layers.dense({inputShape: [1], units: 25, activation: 'relu'}));
    // Add a new hidden layer with 100 neurons, and ReLU activation.
    model.add(tf.layers.dense({units: 5, activation: 'relu'}));
    // Add another dense layer with 1 neuron that will be connected to the previous hidden layer.
    model.add(tf.layers.dense({units: 1}));

    model.summary();

    // Choose a learning rate that is suitable for the data we are using.
    const LEARNING_RATE = 0.0001;
    const OPTIMIZER = tf.train.sgd(LEARNING_RATE);

    function evaluate() {
        // Predict answer for a single piece of data.
        tf.tidy(function() {

            let newInput = normalize(tf.tensor1d([7]), FEATURE_RESULTS.MIN_VALUES, FEATURE_RESULTS.MAX_VALUES);


            let output = model.predict(newInput.NORMALIZED_VALUES);

            output.print();

        });

        // Finally when you no longer need to make any more predictions,
        // clean up the remaining Tensors. 
        FEATURE_RESULTS.MIN_VALUES.dispose();
        FEATURE_RESULTS.MAX_VALUES.dispose();
        model.dispose();

        console.log(tf.memory().numTensors);

    }

    function logProgress(epoch, logs) {
        console.log('Data for epoch ' + epoch, Math.sqrt(logs.loss));
        if (epoch == 70) {
            OPTIMIZER.setLearningRate(LEARNING_RATE / 2);
        }
    }

    async function train() {
        // Compile the model with the defined learning rate and specify
        // our loss function to use.
        model.compile({
            optimizer: OPTIMIZER,
            loss: 'meanSquaredError'
        });

        // Finally do the training itself 
        let results = await model.fit(FEATURE_RESULTS.NORMALIZED_VALUES, OUTPUTS_TENSOR, {
            callbacks: {onEpochEnd: logProgress},
            shuffle: true,  // Ensure data is shuffled in case it was in an order
            batchSize: 2,
            epochs: 200     // Go over the data 200 times!
        });

        OUTPUTS_TENSOR.dispose();
        FEATURE_RESULTS.NORMALIZED_VALUES.dispose();

        console.log("Average error loss: " + Math.sqrt(results.history.loss[results.history.loss.length - 1]));

        evaluate(); // Once trained evaluate the model.
    }
    train();
    ///////////////////////////

    INPUTS_TENSOR.dispose();



</script>

</body>
</html>